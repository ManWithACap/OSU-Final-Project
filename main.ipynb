{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "realTrain legnth: 50000\n",
      "fakeTrain length: 50000\n",
      "realTest length: 10000\n",
      "fakeTest length: 10000\n",
      "xTrain length: 100000\n",
      "yTrain length: 100000\n",
      "xTest length: 20000\n",
      "yTest length: 20000\n"
     ]
    }
   ],
   "source": [
    "# Read training and testing images into arrays\n",
    "realTrain = []\n",
    "fakeTrain = []\n",
    "realTest = []\n",
    "fakeTest = []\n",
    "\n",
    "for filename in os.listdir(\"./data/train/REAL\"):\n",
    "    imgPath = os.path.join(\"./data/train/REAL\", filename)\n",
    "    if os.path.isfile(imgPath):\n",
    "        img = cv2.imread(imgPath)\n",
    "        if img is not None:\n",
    "            realTrain.append(img)\n",
    "\n",
    "for filename in os.listdir(\"./data/train/FAKE\"):\n",
    "    imgPath = os.path.join(\"./data/train/FAKE\", filename)\n",
    "    if os.path.isfile(imgPath):\n",
    "        img = cv2.imread(imgPath)\n",
    "        if img is not None:\n",
    "            fakeTrain.append(img)\n",
    "\n",
    "for filename in os.listdir(\"./data/test/REAL\"):\n",
    "    imgPath = os.path.join(\"./data/test/REAL\", filename)\n",
    "    if os.path.isfile(imgPath):\n",
    "        img = cv2.imread(imgPath)\n",
    "        if img is not None:\n",
    "            realTest.append(img)\n",
    "\n",
    "for filename in os.listdir(\"./data/test/FAKE\"):\n",
    "    imgPath = os.path.join(\"./data/test/FAKE\", filename)\n",
    "    if os.path.isfile(imgPath):\n",
    "        img = cv2.imread(imgPath)\n",
    "        if img is not None:\n",
    "            fakeTest.append(img)\n",
    "\n",
    "realTrain = np.array(realTrain)\n",
    "fakeTrain = np.array(fakeTrain)\n",
    "realTest = np.array(realTest)\n",
    "fakeTest = np.array(fakeTest)\n",
    "\n",
    "xTrain = np.concatenate((realTrain, fakeTrain), axis=0)\n",
    "yTrain = np.concatenate((np.ones(len(realTrain)), np.zeros(len(fakeTrain))))\n",
    "xTest = np.concatenate((realTest, fakeTest), axis=0)\n",
    "yTest = np.concatenate((np.ones(len(realTest)), np.zeros(len(fakeTest))))\n",
    "\n",
    "print(f\"\"\"\n",
    "realTrain legnth: {len(realTrain)}\n",
    "fakeTrain length: {len(fakeTrain)}\n",
    "realTest length: {len(realTest)}\n",
    "fakeTest length: {len(fakeTest)}\n",
    "xTrain length: {len(xTrain)}\n",
    "yTrain length: {len(yTrain)}\n",
    "xTest length: {len(xTest)}\n",
    "yTest length: {len(yTest)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 0.6500 - val_accuracy: 0.8375 - val_loss: 0.3688\n",
      "Epoch 2/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8839 - loss: 0.2776 - val_accuracy: 0.9352 - val_loss: 0.1784\n",
      "Epoch 3/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8996 - loss: 0.2467 - val_accuracy: 0.9314 - val_loss: 0.1848\n",
      "Epoch 4/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2210 - val_accuracy: 0.9733 - val_loss: 0.0789\n",
      "Epoch 5/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2073 - val_accuracy: 0.7531 - val_loss: 0.5723\n",
      "Epoch 6/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.1914 - val_accuracy: 0.9255 - val_loss: 0.1932\n",
      "Epoch 7/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9282 - loss: 0.1803 - val_accuracy: 0.9012 - val_loss: 0.2423\n",
      "Epoch 8/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.1692 - val_accuracy: 0.8154 - val_loss: 0.4808\n",
      "Epoch 9/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9367 - loss: 0.1591 - val_accuracy: 0.8759 - val_loss: 0.3283\n",
      "Epoch 10/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9395 - loss: 0.1511 - val_accuracy: 0.9056 - val_loss: 0.2550\n",
      "Epoch 11/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.1444 - val_accuracy: 0.8243 - val_loss: 0.4478\n",
      "Epoch 12/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.1383 - val_accuracy: 0.8525 - val_loss: 0.3713\n",
      "Epoch 13/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9503 - loss: 0.1278 - val_accuracy: 0.9252 - val_loss: 0.1935\n",
      "Epoch 14/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.1196 - val_accuracy: 0.8511 - val_loss: 0.3820\n",
      "Epoch 15/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9524 - loss: 0.1234 - val_accuracy: 0.9204 - val_loss: 0.1979\n",
      "Epoch 16/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9559 - loss: 0.1145 - val_accuracy: 0.8048 - val_loss: 0.5401\n",
      "Epoch 17/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9584 - loss: 0.1072 - val_accuracy: 0.8783 - val_loss: 0.3619\n",
      "Epoch 18/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9587 - loss: 0.1058 - val_accuracy: 0.9213 - val_loss: 0.2624\n",
      "Epoch 19/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9597 - loss: 0.1028 - val_accuracy: 0.9017 - val_loss: 0.3027\n",
      "Epoch 20/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9621 - loss: 0.1005 - val_accuracy: 0.8877 - val_loss: 0.2833\n",
      "Epoch 21/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9623 - loss: 0.1001 - val_accuracy: 0.8683 - val_loss: 0.4417\n",
      "Epoch 22/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9645 - loss: 0.0944 - val_accuracy: 0.9098 - val_loss: 0.2952\n",
      "Epoch 23/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9671 - loss: 0.0909 - val_accuracy: 0.8959 - val_loss: 0.3354\n",
      "Epoch 24/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9675 - loss: 0.0863 - val_accuracy: 0.8932 - val_loss: 0.3332\n",
      "Epoch 25/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9709 - loss: 0.0794 - val_accuracy: 0.8801 - val_loss: 0.4617\n",
      "Epoch 26/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.0899 - val_accuracy: 0.8900 - val_loss: 0.4276\n",
      "Epoch 27/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9715 - loss: 0.0777 - val_accuracy: 0.8812 - val_loss: 0.4658\n",
      "Epoch 28/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9717 - loss: 0.0780 - val_accuracy: 0.8647 - val_loss: 0.5402\n",
      "Epoch 29/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9717 - loss: 0.0786 - val_accuracy: 0.8666 - val_loss: 0.6281\n",
      "Epoch 30/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.0768 - val_accuracy: 0.8986 - val_loss: 0.2769\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.3035\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0723\n",
      "Test Loss: 0.29065799713134766\n",
      "Test Accuracy: 0.9154499769210815\n",
      "Train Loss: 0.1116485446691513\n",
      "Train Accuracy: 0.9599800109863281\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(xTrain, yTrain, epochs=30, validation_split=0.2)\n",
    "\n",
    "testLoss, testAccuracy = model.evaluate(xTest, yTest)\n",
    "trainLoss, trainAccuracy = model.evaluate(xTrain, yTrain)\n",
    "print(f\"Test Loss: {testLoss}\\nTest Accuracy: {testAccuracy}\")\n",
    "print(f\"Train Loss: {trainLoss}\\nTrain Accuracy: {trainAccuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and export the model\n",
    "model.save(\"img_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake.png\n",
      "frog1.jpg\n",
      "frog2.jpg\n",
      "frog3.png\n",
      "frog4.jpg\n",
      "frog5.jpg\n",
      "frog6.jpg\n",
      "real.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Image 1 prediction: 0.0003023147\n",
      "Image 2 prediction: 0.0000000217\n",
      "Image 3 prediction: 0.0000016659\n",
      "Image 4 prediction: 0.0000041612\n",
      "Image 5 prediction: 0.0000000001\n",
      "Image 6 prediction: 0.0000958420\n",
      "Image 7 prediction: 0.0000008647\n",
      "Image 8 prediction: 0.0000013811\n"
     ]
    }
   ],
   "source": [
    "# Predict new images\n",
    "model = models.load_model(\"./img_classifier.keras\")\n",
    "\n",
    "newImgs = []\n",
    "\n",
    "for filename in os.listdir(\"./data\"):\n",
    "    imgPath = os.path.join(\"./data\", filename)\n",
    "    if os.path.isfile(imgPath):\n",
    "        img = cv2.imread(imgPath)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (32, 32))\n",
    "            newImgs.append(img)\n",
    "            print(filename)\n",
    "\n",
    "newImgs = np.array(newImgs)\n",
    "\n",
    "predictions = model.predict(newImgs)\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Image {i+1} prediction: {pred[0]:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
